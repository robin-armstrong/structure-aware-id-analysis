using LinearAlgebra
using Distributions
using StatsBase
using Random
using PyPlot
using JLD2

include("../../algorithms/rgks.jl")
include("../../algorithms/rid.jl")
include("../../algorithms/rsvd.jl")
include("../../algorithms/levg.jl")
include("../../utilities/plot_config.jl")

####################################################################
##################### SCRIPT PARAMETERS ############################
####################################################################

# path prefix for all output generated by this script
destination = "src/experiments/bandwidth_example/bandwidth_example"
readme      = "Testing interpolative decomposition algorithms on a matrix with a strong trade-off between column norm and leverage score."

rng          = MersenneTwister(1)   # random souce, set for reproducibility
n            = 800
bw_min       = 1.
bw_max       = 600.
krange       = 1:30           # range of approximation ranks to test
k_plot       = 20
numtrials    = 100              # trials per approximation rank

plot_only = false

####################################################################
##################### DATA GENERATION ##############################
####################################################################

function fprintln(s)
    println(s)
    flush(stdout)
end

if(!plot_only)
    function run_bandwidth_example(destination, readme, rng, n, bw_min, bw_max, krange, numtrials, plot_only)
        logstr  = readme*"\n\n"
        logstr *= "rng       = "*string(rng)*"\n"
        logstr *= "n         = "*string(n)*"\n"
        logstr *= "bw_min    = "*string(bw_min)*"\n"
        logstr *= "bw_max    = "*string(bw_max)*"\n"
        logstr *= "krange    = "*string(krange)*"\n"
        logstr *= "numtrials = "*string(numtrials)*"\n"

        fprintln("\n"*logstr)
        
        logfile = destination*"_log.txt"
        touch(logfile)
        io = open(logfile, "w")
        write(logfile, logstr)
        close(io)

        M = zeros(n, n)

        bandwidth = range(bw_min, bw_max, n)

        for i = 1:n
            for j = i:n
                bw      = 1 + n*(.5*(i + j)/n)^2
                c       = exp(-.5*((i - j)/bw)^2)
                M[i, j] = c
                M[j, i] = c
            end
        end

        fprintln("computing SVD of test matrix...")

        testmat_svd = svd(M)

        data   = Dict()
        means  = Dict()
        stds   = Dict()
        quants = Dict()

        for alg in ["dgeqp3", "levg", "rid", "rgks"]
            data[alg]   = zeros(length(krange), numtrials)
            means[alg]  = zeros(length(krange))
            stds[alg]   = zeros(length(krange))
            quants[alg] = zeros(length(krange), 2)
        end

        fprintln("running tests...\n")

        trialcounter = 0

        for t = 1:numtrials
            for i = 1:length(krange)
                trialcounter += 1
                
                k       = krange[i]
                lscores = [norm(testmat_svd.Vt[1:k, j])^2 for j = 1:size(M, 2)]
                lscores = min.(lscores, 1.)
                lscores = max.(lscores, 0.)

                if(trialcounter % 10 == 0)
                    fprintln("   trial "*string(trialcounter)*" out of "*string(numtrials*length(krange)))
                end

                r1 = rgks(rng, M, k, oversamp = ceil(Int64, .1*k))
                r2 = rid(rng, M, k, oversamp = ceil(Int64, .1*k))
                r3 = levg(rng, M, k, oversamp = ceil(Int64, .1*k), leverage_scores = lscores)
                r4 = qr(M, ColumnNorm())

                # optimally reducing the levg approximation to rank k

                U = svd(r3.X).U
                Q = r3.Q*U[:, 1:k]
                X = Q'*M

                # finding the approximation subspace used by DGEQP3
                W = r4.Q*Matrix{Float64}(I(n)[:, 1:k])

                data["rgks"][i, t]    = norm(M - (r1.Q)*(r1.X))
                data["rid"][i, t]     = norm(M - (r2.Q)*(r2.X))
                data["levg"][i, t]    = norm(M - Q*X)
                data["dgeqp3"][i, t]  = norm(M - W*(W'*M))
            end

            @save destination*"_data.jld2" krange numtrials testmat_svd data means stds quants
        end

        fprintln("\ncalculating approximation error statistics...")
        
        for alg in ["dgeqp3", "levg", "rid", "rgks"]
            means[alg]  = vec(mean(data[alg], dims = 2))
            stds[alg]   = vec(std(data[alg], dims = 2))

            for i = 1:length(krange)
                quants[alg][i, 1] = quantile(data[alg][i, :], .05)
                quants[alg][i, 2] = quantile(data[alg][i, :], .95)
            end
        end

        @save destination*"_data.jld2" krange numtrials testmat_svd data means stds quants
    end

    run_bandwidth_example(destination, readme, rng, n, bw_min, bw_max, krange, numtrials, plot_only)
end

####################################################################
##################### PLOTTING #####################################
####################################################################

@load destination*"_data.jld2" krange numtrials testmat_svd data means stds quants

fprintln("plotting error statistics...")

testmat_norm = norm(testmat_svd.S)
optimal      = [norm(testmat_svd.S[(k + 1):end]) for k in krange]

ioff()
fig, (levg_colnorm, norm_rel, heatmap, opt_rel) = subplots(2, 2, figsize = (10, 10))

mfreq      = 5
errbar     = "confidence"   # either "confidence" or "quantile"
confidence = .95

alpha = quantile(Normal(0, 1), 1 - .5*(1 - confidence))

M = testmat_svd.U*Diagonal(testmat_svd.S)*testmat_svd.Vt
heatmap.imshow(M)
heatmap.set_xticks([])
heatmap.set_yticks([])

lscores  = [norm(testmat_svd.Vt[1:k_plot, j]) for j = 1:n]
colnorms = [norm(M[:, j]) for j = 1:n]

levg_colnorm.set_xlabel(L"Leverage Score ($k = 20$)")
levg_colnorm.set_ylabel("Column Norm")
levg_colnorm.scatter(lscores, colnorms)

norm_rel.set_xlabel(L"Approximation Rank ($k$)")
norm_rel.set_ylabel("Relative Frobenius Error")
norm_rel.set_yscale("log")

opt_rel.set_xlabel(L"Approximation Rank ($k$)")
opt_rel.set_ylabel("Frobenius Error Suboptimality")
opt_rel.set_ylim([1., 5.])

for alg in ["levg", "rid", "rgks"]
    norm_rel.plot(krange, means[alg]/testmat_norm, color = algcolors[alg], marker = algmarkers[alg], markevery = mfreq, markerfacecolor = "none", label = alglabels[alg])
    opt_rel.plot(krange, means[alg]./optimal, color = algcolors[alg], marker = algmarkers[alg], markevery = mfreq, markerfacecolor = "none")

    if(errbar == "quantile")
        norm_rel.fill_between(krange, quants[alg][:, 1]/testmat_norm, quants[alg][:, 2]/testmat_norm, color = algcolors[alg], alpha = .2)
        opt_rel.fill_between(krange, quants[alg][:, 1]./optimal, quants[alg][:, 2]./optimal, color = algcolors[alg], alpha = .2)
    elseif(errbar == "confidence")
        norm_rel.fill_between(krange, (means[alg] .+ alpha*stds[alg]/sqrt(numtrials))/testmat_norm, (means[alg] .- alpha*stds[alg]/sqrt(numtrials))/testmat_norm, color = algcolors[alg], alpha = .2)
        opt_rel.fill_between(krange, (means[alg] .+ alpha*stds[alg]/sqrt(numtrials))./optimal, (means[alg] .- alpha*stds[alg]/sqrt(numtrials))./optimal, color = algcolors[alg], alpha = .2)
    else
        throw(ArgumentError("unrecognized error bar type, '"*errbar*"'"))
    end
end

norm_rel.plot(krange, optimal/testmat_norm, color = "black", linestyle = "dashed", label = "Optimal")
norm_rel.legend()

savefig(destination*"_plot.pdf", bbox_inches = "tight")
close(fig)
